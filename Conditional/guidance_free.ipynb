{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dd081c-5ae6-4620-952b-9c8d0970dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "root = '../../data/CIFAR10/'\n",
    "\n",
    "# Load the CIFAR-10\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=root, train=True, transform=transform, download=False)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=root, train=False, transform=transform, download=False)\n",
    "\n",
    "bs = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871e22b-2dde-4f19-bdb4-10d63ca41547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "import math\n",
    "from torch.nn import init\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, T, d_model, dim):\n",
    "        assert d_model % 2 == 0\n",
    "        super().__init__()\n",
    "        emb = torch.arange(0, d_model, step=2) / d_model * math.log(10000)\n",
    "        emb = torch.exp(-emb)\n",
    "        pos = torch.arange(T).float()\n",
    "        emb = pos[:, None] * emb[None, :]\n",
    "        assert list(emb.shape) == [T, d_model // 2]\n",
    "        emb = torch.stack([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "        assert list(emb.shape) == [T, d_model // 2, 2]\n",
    "        emb = emb.view(T, d_model)\n",
    "\n",
    "        self.timembedding = nn.Sequential(\n",
    "            nn.Embedding.from_pretrained(emb, freeze=False),\n",
    "            nn.Linear(d_model, dim),\n",
    "            Swish(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        emb = self.timembedding(t)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class ConditionalEmbedding(nn.Module):\n",
    "    def __init__(self, num_labels, d_model, dim):\n",
    "        assert d_model % 2 == 0\n",
    "        super().__init__()\n",
    "        self.condEmbedding = nn.Sequential(\n",
    "            nn.Embedding(num_embeddings=num_labels + 1, embedding_dim=d_model, padding_idx=0),\n",
    "            nn.Linear(d_model, dim),\n",
    "            Swish(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        emb = self.condEmbedding(t)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1)\n",
    "        self.c2 = nn.Conv2d(in_ch, in_ch, 5, stride=2, padding=2)\n",
    "\n",
    "    def forward(self, x, temb, cemb):\n",
    "        x = self.c1(x) + self.c2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.c = nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1)\n",
    "        self.t = nn.ConvTranspose2d(in_ch, in_ch, 5, 2, 2, 1)\n",
    "\n",
    "    def forward(self, x, temb, cemb):\n",
    "        _, _, H, W = x.shape\n",
    "        x = self.t(x)\n",
    "        x = self.c(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.group_norm = nn.GroupNorm(32, in_ch)\n",
    "        self.proj_q = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_k = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_v = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.group_norm(x)\n",
    "        q = self.proj_q(h)\n",
    "        k = self.proj_k(h)\n",
    "        v = self.proj_v(h)\n",
    "\n",
    "        q = q.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        k = k.view(B, C, H * W)\n",
    "        w = torch.bmm(q, k) * (int(C) ** (-0.5))\n",
    "        assert list(w.shape) == [B, H * W, H * W]\n",
    "        w = F.softmax(w, dim=-1)\n",
    "\n",
    "        v = v.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        h = torch.bmm(w, v)\n",
    "        assert list(h.shape) == [B, H * W, C]\n",
    "        h = h.view(B, H, W, C).permute(0, 3, 1, 2)\n",
    "        h = self.proj(h)\n",
    "\n",
    "        return x + h\n",
    "\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, tdim, dropout, attn=True):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.GroupNorm(32, in_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        self.temb_proj = nn.Sequential(\n",
    "            Swish(),\n",
    "            nn.Linear(tdim, out_ch),\n",
    "        )\n",
    "        self.cond_proj = nn.Sequential(\n",
    "            Swish(),\n",
    "            nn.Linear(tdim, out_ch),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.GroupNorm(32, out_ch),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        if in_ch != out_ch:\n",
    "            self.shortcut = nn.Conv2d(in_ch, out_ch, 1, stride=1, padding=0)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "        if attn:\n",
    "            self.attn = AttnBlock(out_ch)\n",
    "        else:\n",
    "            self.attn = nn.Identity()\n",
    "\n",
    "\n",
    "    def forward(self, x, temb, labels):\n",
    "        h = self.block1(x)\n",
    "        h += self.temb_proj(temb)[:, :, None, None]\n",
    "        h += self.cond_proj(labels)[:, :, None, None]\n",
    "        h = self.block2(h)\n",
    "\n",
    "        h = h + self.shortcut(x)\n",
    "        h = self.attn(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, T, num_labels, ch, ch_mult, num_res_blocks, dropout):\n",
    "        super().__init__()\n",
    "        tdim = ch * 4\n",
    "        self.time_embedding = TimeEmbedding(T, ch, tdim)\n",
    "        self.cond_embedding = ConditionalEmbedding(num_labels, ch, tdim)\n",
    "        self.head = nn.Conv2d(3, ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.downblocks = nn.ModuleList()\n",
    "        chs = [ch]  # record output channel when dowmsample for upsample\n",
    "        now_ch = ch\n",
    "        for i, mult in enumerate(ch_mult):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks):\n",
    "                self.downblocks.append(ResBlock(in_ch=now_ch, out_ch=out_ch, tdim=tdim, dropout=dropout))\n",
    "                now_ch = out_ch\n",
    "                chs.append(now_ch)\n",
    "            if i != len(ch_mult) - 1:\n",
    "                self.downblocks.append(DownSample(now_ch))\n",
    "                chs.append(now_ch)\n",
    "\n",
    "        self.middleblocks = nn.ModuleList([\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=True),\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=False),\n",
    "        ])\n",
    "\n",
    "        self.upblocks = nn.ModuleList()\n",
    "        for i, mult in reversed(list(enumerate(ch_mult))):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks + 1):\n",
    "                self.upblocks.append(ResBlock(in_ch=chs.pop() + now_ch, out_ch=out_ch, tdim=tdim, dropout=dropout, attn=False))\n",
    "                now_ch = out_ch\n",
    "            if i != 0:\n",
    "                self.upblocks.append(UpSample(now_ch))\n",
    "        assert len(chs) == 0\n",
    "\n",
    "        self.tail = nn.Sequential(\n",
    "            nn.GroupNorm(32, now_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(now_ch, 3, 3, stride=1, padding=1)\n",
    "        )\n",
    " \n",
    "\n",
    "    def forward(self, x, t, labels):\n",
    "        # Timestep embedding\n",
    "        temb = self.time_embedding(t)\n",
    "        cemb = self.cond_embedding(labels)\n",
    "        # Downsampling\n",
    "        h = self.head(x)\n",
    "        hs = [h]\n",
    "        for layer in self.downblocks:\n",
    "            h = layer(h, temb, cemb)\n",
    "            hs.append(h)\n",
    "        # Middle\n",
    "        for layer in self.middleblocks:\n",
    "            h = layer(h, temb, cemb)\n",
    "        # Upsampling\n",
    "        for layer in self.upblocks:\n",
    "            if isinstance(layer, ResBlock):\n",
    "                h = torch.cat([h, hs.pop()], dim=1)\n",
    "            h = layer(h, temb, cemb)\n",
    "        h = self.tail(h)\n",
    "\n",
    "        assert len(hs) == 0\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f97a5c-f043-4925-a8fe-ec519eb6ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "beta_1 = 1e-4\n",
    "beta_T = 0.028\n",
    "n_epochs = 500\n",
    "learning_rate = 1e-3\n",
    "w = 1.8\n",
    "p_condi = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b6925-6c8d-4fe4-a906-2babc8d66e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = torch.linspace(beta_1, beta_T, T).double()\n",
    "alphas = 1.0 - betas\n",
    "alphas_bar = torch.cumprod(alphas, dim=0)\n",
    "coeff1 = torch.sqrt(1.0 / alphas)\n",
    "coeff2 = coeff1 * (1.0 - alphas) / torch.sqrt(1.0 - alphas_bar)\n",
    "var = betas * (1.0 - F.pad(alphas_bar, [1, 0], value=1)[:T]) / (1.0 - alphas_bar)\n",
    "sqrt_alphas_bar = torch.sqrt(alphas_bar)\n",
    "sqrt_one_minus_alphas_bar = torch.sqrt(1.0 - alphas_bar)\n",
    "used_var = torch.cat([var[1:2], betas[1:]])\n",
    "used_var1 = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d4b0d-83dc-4ea7-b33b-5799ac6c508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(v, t, x_shape):\n",
    "    device = t.device\n",
    "    out = torch.gather(v, index=t, dim=0).float().to(device)\n",
    "    return out.view([t.shape[0]] + [1] * (len(x_shape) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e284b-0dc4-4734-aec1-27650cb15065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(epsilon, estimated_epsilon):\n",
    "    return torch.sum((epsilon - estimated_epsilon)**2)/len(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb8547-2dd8-4691-acd7-8ea411d52879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def sample(x_T, model, label, w):\n",
    "    x_t = x_T\n",
    "    device = x_t.device\n",
    "    label0 = torch.zeros_like(label).to(label.device)\n",
    "    for time_step in reversed(range(T)):\n",
    "        if(time_step % 100 == 0):\n",
    "            print(time_step)\n",
    "        t = x_t.new_ones([x_T.shape[0], ], dtype=torch.long) * time_step\n",
    "        epsilon = (1 + w) * model(x_t, t, label) - w * model(x_t, t, label0)\n",
    "        mean = extract(coeff1.to(device), t, x_t.shape) * x_t - extract(coeff2.to(device), t, x_t.shape) * epsilon\n",
    "        var = extract(used_var1.to(device), t, x_t.shape)\n",
    "        # no noise when t == 0\n",
    "        if time_step > 0:\n",
    "            noise = torch.randn_like(x_t)\n",
    "        else:\n",
    "            noise = 0\n",
    "        x_t = mean + torch.sqrt(var) * noise\n",
    "        assert torch.isnan(x_t).int().sum() == 0, \"nan in tensor.\"\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a975fabd-d3bd-4469-b558-e82f202578f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(device, model, optimizer):\n",
    "    \n",
    "    begin_time = time.time()\n",
    "    # train\n",
    "    with open('./loss.txt', 'w') as file:\n",
    "        for i in range(n_epochs):\n",
    "            for batch_idx, (x, label) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                x = x.to(device)\n",
    "                label = label.to(device) + 1\n",
    "                if np.random.rand() < p_condi:\n",
    "                    label = torch.zeros_like(label).to(device)\n",
    "                epsilon = torch.randn_like(x).to(device)\n",
    "                t = torch.randint(T, (x.shape[0], )).to(device)\n",
    "                x_t = extract(sqrt_alphas_bar.to(device), t, x.shape) * x + extract(sqrt_one_minus_alphas_bar.to(device), t, x.shape) * epsilon\n",
    "                estimated_epsilon = model(x_t, t, label)\n",
    "                loss_0 = loss(epsilon, estimated_epsilon)\n",
    "                loss_0.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                each_epoch = 1\n",
    "                n_samples = 100\n",
    "                #train\n",
    "                indices = torch.randperm(len(train_dataset))[:n_samples]\n",
    "                x = torch.stack([train_dataset[i][0] for i in indices]).to(device)\n",
    "                label = torch.tensor([train_dataset[i][1] for i in indices]).to(device) + 1\n",
    "                if np.random.rand() < p_condi:\n",
    "                    label = torch.zeros_like(label).to(device)\n",
    "                t = torch.randint(T, (x.shape[0], )).to(device)\n",
    "                epsilon = torch.randn_like(x).to(device)\n",
    "                x_t = extract(sqrt_alphas_bar.to(device), t, x.shape) * x + extract(sqrt_one_minus_alphas_bar.to(device), t, x.shape) * epsilon\n",
    "                estimated_epsilon = model(x_t, t, label)\n",
    "                loss_0 = loss(epsilon, estimated_epsilon)\n",
    "                if(i % each_epoch == 0):\n",
    "                    print(\"epoch: \", i, \", training loss: \", loss_0.item())\n",
    "                file.write(str(loss_0.item()) + ' ')\n",
    "                #test\n",
    "                indices = torch.randperm(len(test_dataset))[:n_samples]\n",
    "                x = torch.stack([test_dataset[i][0] for i in indices]).to(device)\n",
    "                label = torch.tensor([test_dataset[i][1] for i in indices]).to(device) + 1\n",
    "                if np.random.rand() < p_condi:\n",
    "                    label = torch.zeros_like(label).to(device)\n",
    "                t = torch.randint(T, (x.shape[0], )).to(device)\n",
    "                epsilon = torch.randn_like(x).to(device)\n",
    "                x_t = extract(sqrt_alphas_bar.to(device), t, x.shape) * x + extract(sqrt_one_minus_alphas_bar.to(device), t, x.shape) * epsilon\n",
    "                estimated_epsilon = model(x_t, t, label)\n",
    "                loss_0 = loss(epsilon, estimated_epsilon)\n",
    "                if(i % each_epoch == 0):\n",
    "                    print(\"epoch: \", i, \", testing loss: \", loss_0.item())\n",
    "                file.write(str(loss_0.item()) + '\\n')\n",
    "\n",
    "            if(i % each_epoch == 0):\n",
    "                training_time = time.time() - begin_time\n",
    "                minute = int(training_time // 60)\n",
    "                second = int(training_time % 60)\n",
    "                print(f'time loss {minute}:{second}')\n",
    "            \n",
    "            if(i % 10 == 0 or i == n_epochs-1):\n",
    "                torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),}, \n",
    "                './model_and_optimizer.pth'\n",
    "                )\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9f353-42d8-4fe8-82d5-585b8693a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    '''\n",
    "    #start\n",
    "    model = UNet(T=1000, num_labels=10, ch=128, ch_mult=[1, 2, 2, 2], num_res_blocks=2, dropout=0.15).to(device)\n",
    "    optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "    '''\n",
    "    \n",
    "    #round 1: 100 150min\n",
    "    #round 2: 200 300min\n",
    "    #round 3: 200 300min\n",
    "    #round 4: 500 20hr\n",
    "    #round 5: 500 20hr\n",
    "    #round 6: 500 9hr\n",
    "    #round 7: 500 20hr\n",
    "    #totally: 81.5 hr\n",
    "    \n",
    "    #keep training\n",
    "    model = UNet(T=1000, num_labels=10, ch=128, ch_mult=[1, 2, 2, 2], num_res_blocks=2, dropout=0.15).to(device)\n",
    "    optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "    checkpoint = torch.load('./model_and_optimizer.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    \n",
    "    train(device, model, optimizer)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d861120-165d-41b0-bac8-6b93222a96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(T=1000, num_labels=10, ch=128, ch_mult=[1, 2, 2, 2], num_res_blocks=2, dropout=0.15).to(device)\n",
    "checkpoint = torch.load('./model_and_optimizer.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870608bf-03ae-4f1e-aa86-207e42beb0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random guidance-free Generation\n",
    "x = torch.randn((49, 3, 32, 32)).to(device)\n",
    "\n",
    "label = torch.randint(10, (x.shape[0], )) + 1\n",
    "label = label.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    x_0 = sample(x, model, label, w)\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "resized_image = torchvision.transforms.Resize((50, 50))(x_0*0.5 + 0.5)\n",
    "save_image(resized_image, './pictures/genera.png', nrow=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6a8e4-d6f8-45ea-9d65-cd028996a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guidance-free Generation\n",
    "num0 = 3\n",
    "x = torch.randn((num0*10, 3, 32, 32)).to(device)\n",
    "label = torch.tensor([i+1 for i in range(10) for _ in range(num0)]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    x_0 = sample(x, model, label, w)\n",
    "    \n",
    "from torchvision.utils import save_image\n",
    "resized_image = torchvision.transforms.Resize((50, 50))(x_0*0.5 + 0.5)\n",
    "save_image(resized_image, './pictures/guid_genera.png', nrow=num0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f8498c-dd11-456a-a971-2ef251d23d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditional Generation\n",
    "num0 = 3\n",
    "x = torch.randn((num0*10, 3, 32, 32)).to(device)\n",
    "label = torch.tensor([i+1 for i in range(10) for _ in range(num0)]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    x_0 = sample(x, model, label, 0)\n",
    "    \n",
    "from torchvision.utils import save_image\n",
    "resized_image = torchvision.transforms.Resize((50, 50))(x_0*0.5 + 0.5)\n",
    "save_image(resized_image, './pictures/condi_genera.png', nrow=num0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
